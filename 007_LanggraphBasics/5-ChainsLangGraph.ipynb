{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cadenas Usando LangGraph\n",
    "En esta sección veremos cómo podemos construir una cadena simple usando Langgraph que utiliza 4 conceptos importantes:\n",
    "\n",
    "- Cómo usar mensajes de chat como nuestro estado del grafo\n",
    "- Cómo usar modelos de chat en nodos del grafo\n",
    "- Cómo vincular herramientas a nuestro LLM en modelos de chat\n",
    "- Cómo ejecutar las llamadas a herramientas en nuestros nodos del grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos load_dotenv para cargar variables de entorno desde .env\n",
    "from dotenv import load_dotenv\n",
    "# Cargamos las variables de entorno\n",
    "load_dotenv()\n",
    "\n",
    "# Importamos os para gestionar variables de entorno\n",
    "import os\n",
    "# Configuramos la API key de OpenAI desde las variables de entorno\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "# Configuramos la API key de GROQ desde las variables de entorno\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cómo usar mensajes de chat como nuestro estado del grafo\n",
    "##### Mensajes\n",
    "\n",
    "Podemos usar mensajes que pueden capturar diferentes roles dentro de una conversación.\n",
    "LangChain tiene varios tipos de mensajes incluyendo HumanMessage, AIMessage, SystemMessage y ToolMessage.\n",
    "Estos representan un mensaje del usuario, del modelo de chat, para que el modelo de chat instrucciones de comportamiento, y de una llamada a herramienta.\n",
    "\n",
    "Cada mensaje tiene estos componentes importantes:\n",
    "\n",
    "- content - contenido del mensaje\n",
    "- name - Especificar el nombre del autor\n",
    "- response_metadata - opcionalmente, un diccionario de metadatos (por ejemplo, a menudo poblado por el proveedor del modelo para AIMessages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: ModeloLLM\n",
      "\n",
      "Por favor dime cómo puedo ayudarte\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Raul\n",
      "\n",
      "Quiero aprender a programar\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: ModeloLLM\n",
      "\n",
      "¿Qué lenguaje de programación quieres aprender?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Raul\n",
      "\n",
      "Quiero aprender el lenguaje de programación Python\n"
     ]
    }
   ],
   "source": [
    "# Importamos AIMessage y HumanMessage para crear diferentes tipos de mensajes\n",
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "# Importamos pprint para imprimir de forma más legible\n",
    "from pprint import pprint\n",
    "\n",
    "# Creamos una lista de mensajes comenzando con un mensaje del modelo AI\n",
    "messages=[AIMessage(content=f\"Por favor dime cómo puedo ayudarte\",name=\"ModeloLLM\")]\n",
    "# Agregamos un mensaje humano a la conversación\n",
    "messages.append(HumanMessage(content=f\"Quiero aprender a programar\",name=\"Raul\"))\n",
    "# Agregamos otra respuesta del modelo AI\n",
    "messages.append(AIMessage(content=f\"¿Qué lenguaje de programación quieres aprender?\",name=\"ModeloLLM\"))\n",
    "# Agregamos otra pregunta del humano\n",
    "messages.append(HumanMessage(content=f\"Quiero aprender el lenguaje de programación Python\",name=\"Raul\"))\n",
    "\n",
    "# Iteramos sobre todos los mensajes y los imprimimos de forma bonita\n",
    "for message in messages:\n",
    "    message.pretty_print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos de Chat\n",
    "\n",
    "Podemos usar la secuencia de mensajes como entrada con los modelos de chat usando LLM's y OPENAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Udemy\\RAGBootcamp\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importamos ChatGroq para usar el modelo de chat de Groq\n",
    "from langchain_groq import ChatGroq\n",
    "# Inicializamos el modelo de lenguaje con el modelo llama-3.1-8b-instant\n",
    "llm=ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "# Invocamos el modelo con la lista completa de mensajes\n",
    "# El modelo procesará toda la conversación y generará una respuesta\n",
    "result=llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 479,\n",
       "  'prompt_tokens': 85,\n",
       "  'total_tokens': 564,\n",
       "  'completion_time': 0.768095814,\n",
       "  'prompt_time': 0.007119703,\n",
       "  'queue_time': 0.230247229,\n",
       "  'total_time': 0.775215517},\n",
       " 'model_name': 'llama-3.1-8b-instant',\n",
       " 'system_fingerprint': 'fp_ab04adca7d',\n",
       " 'service_tier': 'on_demand',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accedemos a los metadatos de la respuesta\n",
    "# Esto incluye información sobre el uso de tokens, tiempo de procesamiento, etc.\n",
    "result.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Herramientas\n",
    "Las herramientas pueden integrarse con los modelos LLM para interactuar con sistemas externos. Los sistemas externos pueden ser API's, herramientas de terceros.\n",
    "\n",
    "Cuando se hace una consulta, el modelo puede elegir llamar a la herramienta y esta consulta se basa en la \n",
    "entrada de lenguaje natural y esto devolverá una salida que coincide con el esquema de la herramienta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una función simple que suma dos números\n",
    "def add(a:int,b:int)-> int:\n",
    "    \"\"\" Suma a y b\n",
    "    Args:\n",
    "        a (int): primer entero\n",
    "        b (int): segundo entero\n",
    "\n",
    "    Returns:\n",
    "        int: la suma de a y b\n",
    "    \"\"\"\n",
    "    # Retornamos la suma de los dos números\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001F7015D3B30>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001F7017FBAD0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspeccionamos el objeto llm para ver su configuración\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vinculando herramienta con llm\n",
    "\n",
    "# Vinculamos la herramienta 'add' al modelo de lenguaje\n",
    "# Esto permite que el LLM sepa que puede usar esta función\n",
    "llm_with_tools=llm.bind_tools([add])\n",
    "\n",
    "# Invocamos el LLM con una pregunta matemática\n",
    "# El modelo detectará que necesita usar la herramienta 'add'\n",
    "tool_call=llm_with_tools.invoke([HumanMessage(content=f\"¿Cuánto es 2 más 2?\",name=\"Raul\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'a': 2, 'b': 2},\n",
       "  'id': 'akw0nky1t',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificamos las llamadas a herramientas que el modelo decidió hacer\n",
    "# Aquí veremos que el modelo llamó a 'add' con los argumentos a=2 y b=2\n",
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando mensajes como estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos TypedDict para definir la estructura del estado\n",
    "from typing_extensions import TypedDict\n",
    "# Importamos AnyMessage que puede ser cualquier tipo de mensaje\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "# Definimos la clase State con un campo 'message' que es una lista de mensajes\n",
    "class State(TypedDict):\n",
    "    message:list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reductores\n",
    "¡Ahora, tenemos un problema menor!\n",
    "\n",
    "Como discutimos, cada nodo devolverá un nuevo valor para nuestra clave de estado messages.\n",
    "\n",
    "Pero, este nuevo valor sobrescribirá el valor anterior de messages.\n",
    "\n",
    "A medida que se ejecuta nuestro grafo, queremos agregar mensajes a nuestra clave de estado messages.\n",
    "\n",
    "Podemos usar funciones reductoras para abordar esto.\n",
    "\n",
    "Los reductores nos permiten especificar cómo se realizan las actualizaciones de estado.\n",
    "\n",
    "Si no se especifica una función reductora, entonces se asume que las actualizaciones a la clave deben sobrescribirla como vimos antes.\n",
    "\n",
    "Pero, para agregar mensajes, podemos usar el reductor precompilado add_messages.\n",
    "\n",
    "Esto asegura que cualquier mensaje se agregue a la lista existente de mensajes.\n",
    "\n",
    "Simplemente necesitamos anotar nuestra clave messages con la función reductora add_messages como metadato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos add_messages, el reductor precompilado para agregar mensajes\n",
    "from langgraph.graph.message import add_messages\n",
    "# Importamos Annotated para agregar metadatos a los tipos\n",
    "from typing import Annotated\n",
    "# Redefinimos State con el reductor add_messages\n",
    "class State(TypedDict):\n",
    "    # Anotamos messages con add_messages para que los mensajes se agreguen en lugar de sobrescribirse\n",
    "    messages:Annotated[list[AnyMessage],add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reductores con add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Por favor dime cómo puedo ayudarte', additional_kwargs={}, response_metadata={}, name='ModeloLLM'),\n",
       " HumanMessage(content='Quiero aprender a programar', additional_kwargs={}, response_metadata={}, name='Raul')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos una lista inicial de mensajes\n",
    "initial_messages=[AIMessage(content=f\"Por favor dime cómo puedo ayudarte\",name=\"ModeloLLM\")]\n",
    "# Agregamos un mensaje humano\n",
    "initial_messages.append(HumanMessage(content=f\"Quiero aprender a programar\",name=\"Raul\"))\n",
    "# Mostramos los mensajes iniciales\n",
    "initial_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='¿Qué lenguaje de programación quieres aprender?', additional_kwargs={}, response_metadata={}, name='ModeloLLM')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos un nuevo mensaje AI que queremos agregar\n",
    "ai_message=AIMessage(content=f\"¿Qué lenguaje de programación quieres aprender?\",name=\"ModeloLLM\")\n",
    "# Mostramos el mensaje\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Por favor dime cómo puedo ayudarte', additional_kwargs={}, response_metadata={}, name='ModeloLLM', id='7ae0d5f1-e208-4e21-bfbc-7276d304f11a'),\n",
       " HumanMessage(content='Quiero aprender a programar', additional_kwargs={}, response_metadata={}, name='Raul', id='67387a30-57f3-4d02-9918-06939d3c64e6'),\n",
       " AIMessage(content='¿Qué lenguaje de programación quieres aprender?', additional_kwargs={}, response_metadata={}, name='ModeloLLM', id='2e58f59c-412a-45c5-8555-addff6e9d9a1')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El reductor add_messages agrega mensajes en lugar de sobrescribirlos\n",
    "# Aquí combinamos initial_messages con ai_message\n",
    "# El resultado será una lista con todos los mensajes combinados\n",
    "add_messages(initial_messages,ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la funcionalidad del nodo del chatbot\n",
    "def llm_tool(state:State):\n",
    "    # Invocamos el LLM con herramientas usando los mensajes del estado\n",
    "    # Retornamos un diccionario con los nuevos mensajes que se agregarán al estado\n",
    "    return {\"messages\":[llm_with_tools.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importamos Image y display para visualizar el grafo\n",
    "from IPython.display import Image, display\n",
    "# Importamos los componentes de LangGraph\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "# Creamos el constructor del grafo con el estado definido\n",
    "builder=StateGraph(State)\n",
    "\n",
    "# Agregamos el nodo \"llm_tool\" que ejecuta la función llm_tool\n",
    "builder.add_node(\"llm_tool\",llm_tool)\n",
    "\n",
    "# Conectamos START al nodo \"llm_tool\"\n",
    "builder.add_edge(START,\"llm_tool\")\n",
    "# Conectamos \"llm_tool\" al nodo END\n",
    "builder.add_edge(\"llm_tool\",END)\n",
    "\n",
    "# Compilamos el grafo\n",
    "graph=builder.compile()\n",
    "\n",
    "# Mostramos el diagrama del grafo\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "¿Cuánto es 2 más 2?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (xqtjqz0rm)\n",
      " Call ID: xqtjqz0rm\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 2\n"
     ]
    }
   ],
   "source": [
    "# Invocación del grafo\n",
    "\n",
    "# Invocamos el grafo con una pregunta matemática\n",
    "messages=graph.invoke({\"messages\":\"¿Cuánto es 2 más 2?\"})\n",
    "\n",
    "# Iteramos sobre todos los mensajes resultantes y los imprimimos\n",
    "for message in messages[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una lista de herramientas disponibles\n",
    "# En este caso solo tenemos la función 'add'\n",
    "tools=[add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos ToolNode para crear un nodo que ejecuta herramientas\n",
    "from langgraph.prebuilt import ToolNode\n",
    "# Importamos tools_condition para enrutar condicionalmente según si hay llamadas a herramientas\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# Creamos un nuevo constructor del grafo\n",
    "builder=StateGraph(State)\n",
    "\n",
    "## Agregamos nodos\n",
    "\n",
    "# Agregamos el nodo \"llm_tool\" que llama al LLM con herramientas\n",
    "builder.add_node(\"llm_tool\",llm_tool)\n",
    "# Agregamos el nodo \"tools\" que ejecuta las herramientas llamadas\n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "## Agregamos Aristas\n",
    "# Conectamos START al nodo \"llm_tool\"\n",
    "builder.add_edge(START,\"llm_tool\")\n",
    "# Agregamos aristas condicionales desde \"llm_tool\"\n",
    "builder.add_conditional_edges(\n",
    "    \"llm_tool\",\n",
    "    # Si el último mensaje (resultado) del asistente es una llamada a herramienta -> tools_condition enruta a tools\n",
    "    # Si el último mensaje (resultado) del asistente NO es una llamada a herramienta -> tools_condition enruta a END\n",
    "    tools_condition\n",
    ")\n",
    "# Conectamos \"tools\" a END después de ejecutar la herramienta\n",
    "builder.add_edge(\"tools\",END)\n",
    "\n",
    "# Compilamos el grafo\n",
    "graph_builder = builder.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mostramos el diagrama del grafo con enrutamiento condicional\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "¿Cuánto es 2 más 2?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (vz9e7yx30)\n",
      " Call ID: vz9e7yx30\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 2\n"
     ]
    }
   ],
   "source": [
    "# Invocación del grafo con ejecución de herramientas\n",
    "\n",
    "# Invocamos el grafo con una pregunta matemática\n",
    "messages=graph.invoke({\"messages\":\"¿Cuánto es 2 más 2?\"})\n",
    "\n",
    "# Iteramos sobre todos los mensajes (pregunta, llamada a herramienta y resultado)\n",
    "for message in messages[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "¿Qué es Machine Learning?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<brave_search> Machine Learning\n"
     ]
    }
   ],
   "source": [
    "# Invocamos el grafo con una pregunta que NO requiere herramientas\n",
    "# El modelo responderá directamente sin llamar a la herramienta 'add'\n",
    "messages=graph.invoke({\"messages\":\"¿Qué es Machine Learning?\"})\n",
    "\n",
    "# Iteramos sobre los mensajes de la conversación\n",
    "for message in messages[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
