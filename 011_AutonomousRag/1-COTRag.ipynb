{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb44e558",
   "metadata": {},
   "source": [
    "#### Cadena de Pensamientos con RAG (Chain of Thoughts with RAG)\n",
    "\n",
    "### ¬øQu√© es Chain-of-Thought (CoT) en RAG?\n",
    "\n",
    "**CoT (Cadena de Pensamientos)** en RAG descompone una pregunta compleja en pasos intermedios, permitiendo recuperaci√≥n + reflexi√≥n en cada paso antes de responder.\n",
    "\n",
    "Este enfoque imita el razonamiento humano al dividir problemas complejos en sub-problemas m√°s manejables.\n",
    "\n",
    "### üîÑ Flujo de CoT RAG:\n",
    "\n",
    "```\n",
    "Consulta del Usuario\n",
    "   ‚Üì\n",
    "Paso 1: Descomponer pregunta ‚Üí sub-pasos (Razonar)\n",
    "   ‚Üì\n",
    "Paso 2: Recuperar documentos por cada paso (Actuar)\n",
    "   ‚Üì\n",
    "Paso 3: Combinar contexto (Observar)\n",
    "   ‚Üì\n",
    "Paso 4: Generaci√≥n de respuesta final (Reflexionar)\n",
    "```\n",
    "\n",
    "### üéØ Ventajas de CoT RAG:\n",
    "- ‚úÖ Mejor manejo de preguntas complejas\n",
    "- ‚úÖ Razonamiento m√°s transparente y explicable\n",
    "- ‚úÖ Recuperaci√≥n m√°s precisa por sub-pregunta\n",
    "- ‚úÖ Respuestas m√°s fundamentadas y coherentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1cb1a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Udemy\\RAGBootcamp\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importar librer√≠as del sistema operativo\n",
    "import os  # Para manejo de variables de entorno\n",
    "\n",
    "# Importar tipos para anotaciones\n",
    "from typing import List  # Para definir listas tipadas\n",
    "\n",
    "# Importar Pydantic para validaci√≥n de datos\n",
    "from pydantic import BaseModel  # Clase base para modelos con validaci√≥n autom√°tica\n",
    "\n",
    "# Importar clases de LangChain\n",
    "from langchain.schema import Document  # Clase para representar documentos\n",
    "\n",
    "# Importar embeddings de OpenAI\n",
    "from langchain_openai import OpenAIEmbeddings  # Modelo de embeddings para vectorizaci√≥n\n",
    "\n",
    "# Importar cargadores de documentos\n",
    "from langchain_community.document_loaders import TextLoader  # Cargador de archivos de texto\n",
    "\n",
    "# Importar base de datos vectorial FAISS\n",
    "from langchain.vectorstores import FAISS  # Vector store eficiente de Facebook\n",
    "\n",
    "# Importar divisor de texto\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Divisi√≥n recursiva de documentos\n",
    "\n",
    "# Importar componentes de LangGraph\n",
    "from langgraph.graph import StateGraph, END  # StateGraph para grafos de estado, END para nodo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "742cd685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. Preparar el Vectorstore (Base de Datos Vectorial)\n",
    "# -------------------------------\n",
    "\n",
    "# Cargar documentos desde archivo de texto con codificaci√≥n UTF-8\n",
    "# \"research_notes.txt\" contiene notas de investigaci√≥n sobre transformers\n",
    "docs = TextLoader(\"research_notes.txt\", encoding=\"utf-8\").load()\n",
    "\n",
    "# Crear divisor de texto recursivo con par√°metros espec√≠ficos\n",
    "# chunk_size=500: cada fragmento tendr√° m√°ximo 500 caracteres\n",
    "# chunk_overlap=50: superposici√≥n de 50 caracteres entre fragmentos para mantener contexto\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "# Dividir los documentos en fragmentos (chunks) m√°s peque√±os\n",
    "# Esto permite b√∫squedas m√°s precisas y granulares\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "# Inicializar el modelo de embeddings de OpenAI\n",
    "# Este modelo convierte texto en vectores num√©ricos de alta dimensi√≥n\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# Crear base de datos vectorial FAISS a partir de los fragmentos\n",
    "# FAISS indexa los embeddings para b√∫squedas de similitud r√°pidas\n",
    "# from_documents() autom√°ticamente genera embeddings y crea el √≠ndice\n",
    "vectorstore = FAISS.from_documents(chunks, embedding)\n",
    "\n",
    "# Convertir el vectorstore en un retriever (recuperador)\n",
    "# El retriever proporciona una interfaz simple para b√∫squedas de similitud\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "881c7baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar m√≥dulo os para variables de entorno\n",
    "import os\n",
    "\n",
    "# Importar funci√≥n para inicializar modelos de chat de manera gen√©rica\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Importar load_dotenv para cargar variables desde archivo .env\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Configurar la API key de OpenAI desde las variables de entorno\n",
    "# Esto permite autenticar las solicitudes a la API de OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Inicializar el modelo de lenguaje GPT-4o de OpenAI\n",
    "# Este modelo ser√° el \"cerebro\" que razona y genera respuestas\n",
    "# init_chat_model permite usar diferentes proveedores con la misma interfaz\n",
    "llm = init_chat_model(\"openai:gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd17f2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2. Definici√≥n del Estado de LangGraph\n",
    "# -------------------------------\n",
    "\n",
    "# Definir la clase de estado para el sistema CoT RAG\n",
    "# Esta clase hereda de BaseModel de Pydantic para validaci√≥n autom√°tica\n",
    "class RAGCoTState(BaseModel):\n",
    "    \"\"\"\n",
    "    Estado que fluye a trav√©s del grafo de Chain-of-Thought RAG.\n",
    "    \n",
    "    Attributes:\n",
    "        question: La pregunta compleja original del usuario\n",
    "        sub_steps: Lista de sub-preguntas o pasos de razonamiento generados\n",
    "        retrieved_docs: Lista de documentos recuperados para todos los sub-pasos\n",
    "        answer: La respuesta final sintetizada\n",
    "    \"\"\"\n",
    "    # La pregunta original completa del usuario\n",
    "    question: str\n",
    "    \n",
    "    # Lista de sub-pasos o sub-preguntas para descomponer el problema\n",
    "    # Se inicializa como lista vac√≠a por defecto\n",
    "    sub_steps: List[str] = []\n",
    "    \n",
    "    # Lista de todos los documentos recuperados de cada sub-paso\n",
    "    # Se inicializa como lista vac√≠a por defecto\n",
    "    retrieved_docs: List[Document] = []\n",
    "    \n",
    "    # La respuesta final generada despu√©s del razonamiento CoT\n",
    "    # Se inicializa como string vac√≠o por defecto\n",
    "    answer: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "454347b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 3. Nodos del Grafo CoT RAG\n",
    "# -------------------------------\n",
    "\n",
    "# a. Planificar sub-preguntas (Nodo Planner)\n",
    "def plan_steps(state: RAGCoTState) -> RAGCoTState:\n",
    "    \"\"\"\n",
    "    Descompone la pregunta compleja en 2-3 pasos de razonamiento.\n",
    "    \n",
    "    Este nodo es crucial para CoT porque:\n",
    "    - Divide problemas complejos en partes manejables\n",
    "    - Permite recuperaci√≥n enfocada en cada aspecto\n",
    "    - Facilita razonamiento paso a paso\n",
    "    \n",
    "    Args:\n",
    "        state: Estado actual con la pregunta original\n",
    "        \n",
    "    Returns:\n",
    "        Estado actualizado con sub_steps poblado\n",
    "    \"\"\"\n",
    "    # Construir prompt que solicita al LLM descomponer la pregunta\n",
    "    # Le pedimos expl√≠citamente 2-3 pasos de razonamiento\n",
    "    prompt = f\"Divide la pregunta en 2-3 pasos de razonamiento: \\n\\n {state.question}\"\n",
    "    \n",
    "    # Invocar el LLM con el prompt y obtener el contenido de la respuesta\n",
    "    result = llm.invoke(prompt).content\n",
    "    \n",
    "    # Procesar la respuesta del LLM para extraer los sub-pasos\n",
    "    # - split(\"\\n\"): divide por saltos de l√≠nea\n",
    "    # - line.strip(): elimina espacios en blanco\n",
    "    # - line.strip(\"- \"): elimina guiones y espacios (formato de lista)\n",
    "    # - if line.strip(): solo incluye l√≠neas no vac√≠as\n",
    "    subqs = [line.strip(\"- \") for line in result.split(\"\\n\") if line.strip()]\n",
    "\n",
    "    # Retornar estado actualizado con los sub-pasos\n",
    "    # model_copy() crea una copia del estado con los campos actualizados\n",
    "    return state.model_copy(update={\"sub_steps\": subqs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0e99b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Recuperar documentos para cada paso (Nodo Retriever)\n",
    "def retrieve_per_step(state: RAGCoTState) -> RAGCoTState:\n",
    "    \"\"\"\n",
    "    Recupera documentos relevantes para cada sub-paso generado.\n",
    "    \n",
    "    Esta funci√≥n implementa recuperaci√≥n multi-paso:\n",
    "    - Itera sobre cada sub-pregunta\n",
    "    - Busca documentos relevantes para cada una\n",
    "    - Acumula todos los documentos encontrados\n",
    "    \n",
    "    Args:\n",
    "        state: Estado actual con sub_steps definidos\n",
    "        \n",
    "    Returns:\n",
    "        Estado actualizado con retrieved_docs poblado\n",
    "    \"\"\"\n",
    "    # Inicializar lista para acumular todos los documentos\n",
    "    all_docs = []\n",
    "    \n",
    "    # Iterar sobre cada sub-paso de razonamiento\n",
    "    for sub in state.sub_steps:\n",
    "        # Invocar el retriever con el sub-paso como consulta\n",
    "        # Esto busca documentos relevantes espec√≠ficamente para este sub-paso\n",
    "        docs = retriever.invoke(sub)\n",
    "        \n",
    "        # Agregar los documentos encontrados a la lista acumulada\n",
    "        # extend() agrega todos los elementos de docs a all_docs\n",
    "        all_docs.extend(docs)\n",
    "    \n",
    "    # Retornar estado actualizado con todos los documentos recuperados\n",
    "    # Estos documentos servir√°n como contexto para la generaci√≥n final\n",
    "    return state.model_copy(update={\"retrieved_docs\": all_docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "285a8a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. Generar Respuesta Final (Nodo Responder)\n",
    "def generate_answer(state: RAGCoTState) -> RAGCoTState:\n",
    "    \"\"\"\n",
    "    Sintetiza una respuesta final basada en el razonamiento CoT y documentos recuperados.\n",
    "    \n",
    "    Este nodo:\n",
    "    - Combina todo el contexto recuperado\n",
    "    - Usa la pregunta original y el contexto para generar respuesta\n",
    "    - Produce una respuesta bien razonada y fundamentada\n",
    "    \n",
    "    Args:\n",
    "        state: Estado con pregunta, sub_steps y retrieved_docs\n",
    "        \n",
    "    Returns:\n",
    "        Estado actualizado con la respuesta final\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construir el contexto concatenando el contenido de todos los documentos\n",
    "    # \"\\n\\n\".join() une los textos con doble salto de l√≠nea para legibilidad\n",
    "    # Iteramos sobre cada documento y extraemos su page_content\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in state.retrieved_docs])\n",
    "    \n",
    "    # Construir el prompt para generaci√≥n final\n",
    "    # Este prompt incluye:\n",
    "    # 1. Instrucciones claras sobre el uso de razonamiento\n",
    "    # 2. La pregunta original del usuario\n",
    "    # 3. Todo el contexto recuperado de los sub-pasos\n",
    "    # 4. Solicitud de s√≠ntesis razonada\n",
    "    prompt = f\"\"\"\n",
    "Est√°s respondiendo una pregunta compleja usando razonamiento y documentos recuperados.\n",
    "\n",
    "Pregunta: {state.question}\n",
    "\n",
    "Informaci√≥n Relevante:\n",
    "{context}\n",
    "\n",
    "Ahora sintetiza una respuesta final bien razonada.\n",
    "\"\"\"\n",
    "    \n",
    "    # Invocar el LLM con el prompt construido\n",
    "    # El LLM procesar√° toda la informaci√≥n y generar√° una respuesta coherente\n",
    "    # .content extrae el texto de la respuesta\n",
    "    # .strip() elimina espacios en blanco adicionales\n",
    "    result = llm.invoke(prompt).content.strip()\n",
    "    \n",
    "    # Retornar estado actualizado con la respuesta final\n",
    "    # Esta es la culminaci√≥n del proceso CoT RAG\n",
    "    return state.model_copy(update={\"answer\": result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e382179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000028EA85A8E60>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 4. Construcci√≥n del Grafo LangGraph\n",
    "# -------------------------------\n",
    "\n",
    "# Inicializar el constructor del grafo con el esquema de estado RAGCoTState\n",
    "# StateGraph gestiona el flujo de ejecuci√≥n y la propagaci√≥n del estado\n",
    "builder = StateGraph(RAGCoTState)\n",
    "\n",
    "# Agregar el nodo \"planner\" que ejecuta plan_steps\n",
    "# Este nodo descompone la pregunta compleja en sub-pasos de razonamiento\n",
    "builder.add_node(\"planner\", plan_steps)\n",
    "\n",
    "# Agregar el nodo \"retriever\" que ejecuta retrieve_per_step\n",
    "# Este nodo recupera documentos relevantes para cada sub-paso\n",
    "builder.add_node(\"retriever\", retrieve_per_step)\n",
    "\n",
    "# Agregar el nodo \"responder\" que ejecuta generate_answer\n",
    "# Este nodo sintetiza la respuesta final basada en todo el contexto\n",
    "builder.add_node(\"responder\", generate_answer)\n",
    "\n",
    "# Establecer \"planner\" como punto de entrada del grafo\n",
    "# El flujo siempre comenzar√° descomponiendo la pregunta\n",
    "builder.set_entry_point(\"planner\")\n",
    "\n",
    "# Agregar arista desde \"planner\" a \"retriever\"\n",
    "# Despu√©s de planificar, se procede a recuperar documentos\n",
    "builder.add_edge(\"planner\", \"retriever\")\n",
    "\n",
    "# Agregar arista desde \"retriever\" a \"responder\"\n",
    "# Despu√©s de recuperar, se genera la respuesta final\n",
    "builder.add_edge(\"retriever\", \"responder\")\n",
    "\n",
    "# Agregar arista desde \"responder\" a END\n",
    "# Despu√©s de generar la respuesta, el grafo termina\n",
    "builder.add_edge(\"responder\", END)\n",
    "\n",
    "# Compilar el grafo en un objeto ejecutable\n",
    "# compile() valida y optimiza el grafo para ejecuci√≥n\n",
    "graph = builder.compile()\n",
    "\n",
    "# Mostrar el grafo para visualizar su estructura\n",
    "# Esto puede generar un diagrama del flujo: planner ‚Üí retriever ‚Üí responder ‚Üí END\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6b197df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü™ú Pasos de Razonamiento: ['Para abordar la pregunta sobre los experimentos adicionales en la evaluaci√≥n de Transformers, podemos dividir el razonamiento en los siguientes pasos:', '1. **Identificar los objetivos de evaluaci√≥n**:', 'Antes de dise√±ar experimentos adicionales, es fundamental entender qu√© aspectos espec√≠ficos de los Transformers se quieren evaluar. Esto puede incluir la evaluaci√≥n del rendimiento general en diferentes tareas de procesamiento de lenguaje natural, la eficiencia computacional, la capacidad de generalizaci√≥n, la interpretabilidad, etc.', '2. **Dise√±ar experimentos espec√≠ficos**:', 'Con los objetivos en mente, se pueden dise√±ar experimentos espec√≠ficos que aporten informaci√≥n adicional sobre el modelo. Esto podr√≠a incluir:', '**An√°lisis de robustez**: Probar el modelo con datos ruidosos, alterados o adversarios para evaluar su robustez.', '**Evaluaciones cruzadas de tareas**: Probar el modelo en tareas y dominios no vistos durante el entrenamiento para explorar su capacidad de generalizaci√≥n.', '**Estudio de la escalabilidad**: Investigar c√≥mo el rendimiento se ve afectado por cambios en el tama√±o del modelo o el conjunto de datos.', '**Evaluaci√≥n del impacto de la arquitectura**: Probar variaciones en la arquitectura del Transformer (como diferentes configuraciones de capas o cabezas de atenci√≥n) para ver c√≥mo afectan al rendimiento.', '3. **An√°lisis cualitativo y cuantitativo**:', 'Realizar un an√°lisis tanto cualitativo como cuantitativo de los resultados obtenidos en los experimentos. Esto implica:', '**Cuantitativo**: Medir m√©tricas comunes como precisi√≥n, cobertura o F1 para evaluar el rendimiento.', '**Cualitativo**: Analizar ejemplos o casos espec√≠ficos para obtener insights sobre el comportamiento del modelo, especialmente en situaciones en las que puede fallar o sorprender.', 'Combinar estos pasos permitir√° obtener una comprensi√≥n m√°s completa de las capacidades y limitaciones de los modelos Transformer evaluados.']\n",
      "\n",
      "‚úÖ Respuesta Final:\n",
      " Para evaluar el rendimiento y efectividad de los modelos Transformers, se han realizado varios experimentos adicionales en distintos aspectos t√©cnicos y pr√°cticos. A continuaci√≥n, se destacan los experimentos m√°s relevantes:\n",
      "\n",
      "1. **FlashAttention2**: Esta t√©cnica fue integrada en el modelo LLaMA2, logrando reducir la latencia del contexto en aproximadamente un 50%. Esto es crucial para mejorar la eficiencia en el procesamiento de datos secuenciales largos.\n",
      "\n",
      "2. **Chain-of-Thought Prompting**: Esta estrategia supera al m√©todo tradicional de respuestas directas en tareas l√≥gicas en un 8%, mientras que el \"reflective prompting\" incrementa la precisi√≥n en un 3%. Esto indica que el encadenamiento de pensamientos puede mejorar la capacidad del modelo para razonar a trav√©s de problemas complejos.\n",
      "\n",
      "3. **Tool-Augmented Prompting**: Al integrar LangGraph con Wikipedia y b√∫squedas en SQL, este enfoque permite un razonamiento din√°mico de recuperaci√≥n-agente, lo que facilita obtener y verificar insights complejos del cliente, utilizando bases de datos y verificaciones cruzadas con art√≠culos de Wikipedia.\n",
      "\n",
      "4. **Protocolos de Evaluaci√≥n Humana**: Se utilizan anotadores internos que califican aspectos como la fluidez, la utilidad y la correcci√≥n de las respuestas generadas por los modelos. Adicionalmente, GPT-4 se emplea como evaluador sint√©tico para validar la calidad de las respuestas generadas.\n",
      "\n",
      "5. **Experimentos de Recuperaci√≥n**: Se examin√≥ el rendimiento de buscadores h√≠bridos densos y dispersos, comparando Weaviate con FAISS y BM25. Aunque FAISS ofrece mayor eficiencia, Weaviate es √∫til para filtrados gracias a su integraci√≥n con GraphQL.\n",
      "\n",
      "6. **Tuning con LoRA**: Utilizado para ajustar finamente los modelos de adaptador, reduciendo el consumo de memoria GPU en un 60%, lo cual es significativo para hacer viable el deployment de modelos en entornos con restricciones de hardware.\n",
      "\n",
      "7. **Seguridad**: Incluye detecci√≥n de toxicidad mediante Detoxify y filtros de √°mbito mediante un clasificador de cero disparos. Tambi√©n se implementaron pruebas contrarias mediante \"red teaming\" para asegurar la robustez del modelo contra instrucciones adversar√≠as.\n",
      "\n",
      "Cada uno de estos experimentos y t√©cnicas de evaluaci√≥n contribuye a comprender mejor las capacidades y limitaciones de los modelos Transformers, tanto en t√©rminos de rendimiento t√©cnico como en su aplicaci√≥n pr√°ctica en diversas tareas de procesamiento del lenguaje natural. En conjunto, estos m√©todos buscan garantizar que los modelos no s√≥lo sean eficientes y precisos, sino tambi√©n seguros y aplicables a contextos de alto nivel de exigencia, como por ejemplo en entornos de atenci√≥n al cliente y chatbots.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 5. Ejecutar el Agente CoT RAG\n",
    "# -------------------------------\n",
    "\n",
    "# Bloque principal que se ejecuta solo si el script se ejecuta directamente\n",
    "if __name__ == \"__main__\":\n",
    "    # Definir la consulta compleja del usuario\n",
    "    # Esta pregunta es deliberadamente compleja y requiere razonamiento multi-paso\n",
    "    # Nota: hay un typo en \"eperiments\" y \"eveluation\" (deber√≠a ser \"experiments\" y \"evaluation\")\n",
    "    query = \"¬øCu√°les son los experimentos adicionales en la evaluaci√≥n de Transformers?\"\n",
    "    \n",
    "    # Crear el estado inicial del grafo\n",
    "    # Inicializamos RAGCoTState con la pregunta del usuario\n",
    "    # Los campos sub_steps, retrieved_docs y answer comenzar√°n vac√≠os\n",
    "    state = RAGCoTState(question=query)\n",
    "    \n",
    "    # Ejecutar el grafo completo con el estado inicial\n",
    "    # invoke() ejecuta el grafo de principio a fin:\n",
    "    #   1. Nodo \"planner\": descompone la pregunta en sub-pasos\n",
    "    #   2. Nodo \"retriever\": recupera documentos para cada sub-paso\n",
    "    #   3. Nodo \"responder\": genera respuesta final sintetizada\n",
    "    # Retorna el estado final con todos los campos completados\n",
    "    final = graph.invoke(state)\n",
    "\n",
    "    # Imprimir los pasos de razonamiento generados\n",
    "    # Esto muestra c√≥mo el sistema descompuso la pregunta compleja\n",
    "    print(\"\\nü™ú Pasos de Razonamiento:\", final[\"sub_steps\"])\n",
    "    \n",
    "    # Imprimir la respuesta final generada\n",
    "    # Esta respuesta fue construida considerando todos los sub-pasos y documentos recuperados\n",
    "    print(\"\\n‚úÖ Respuesta Final:\\n\", final[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c310afd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
