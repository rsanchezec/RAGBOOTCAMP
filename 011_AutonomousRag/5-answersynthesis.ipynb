{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üß† S√≠ntesis de Respuestas desde M√∫ltiples Fuentes\n",
        "‚úÖ ¬øQu√© es?\n",
        "\n",
        "La s√≠ntesis de respuestas desde m√∫ltiples fuentes es el proceso donde un agente de IA recopila informaci√≥n de diferentes herramientas de recuperaci√≥n o bases de conocimiento, y fusiona esa informaci√≥n en una √∫nica respuesta coherente y contextualmente rica.\n",
        "\n",
        "Esta es una capacidad fundamental en RAG Ag√©ntico, donde el sistema es m√°s que un simple recuperador ‚Äî planifica, recupera, y luego sintetiza una respuesta que se nutre de m√∫ltiples fuentes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üéØ Por qu√© es necesario\n",
        "La mayor√≠a de las consultas del mundo real son:\n",
        "- Multifac√©ticas (requieren m√∫ltiples tipos de informaci√≥n)\n",
        "- Ambiguas o incompletas (necesitan refinamiento)\n",
        "- Abiertas (no se mapean a un solo documento o fuente)\n",
        "\n",
        "üîç Esto hace que recuperar desde una sola base de datos vectorial sea insuficiente.\n",
        "\n",
        "En su lugar, queremos un agente que pueda:\n",
        "\n",
        "- Decidir qu√© obtener y de d√≥nde (planificaci√≥n de recuperaci√≥n)\n",
        "- Recuperar contenido de m√∫ltiples herramientas (ej., Wikipedia, PDFs, APIs, SQL)\n",
        "- Evaluar y fusionar ese contexto\n",
        "- Producir una √∫nica respuesta similar a la humana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importaci√≥n del m√≥dulo os para interactuar con el sistema operativo (variables de entorno, rutas, etc.)\n",
        "import os\n",
        "\n",
        "# Importaci√≥n de List desde typing para definir tipos de datos (listas tipadas)\n",
        "from typing import List\n",
        "\n",
        "# Importaci√≥n de BaseModel desde pydantic para crear modelos de datos con validaci√≥n autom√°tica\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# Importaci√≥n de init_chat_model para inicializar modelos de chat de diferentes proveedores\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "# Importaci√≥n de OpenAIEmbeddings para generar embeddings (representaciones vectoriales) usando la API de OpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Importaci√≥n de Document, la clase base de LangChain para representar documentos con contenido y metadatos\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Importaci√≥n de FAISS, una biblioteca de Facebook para b√∫squeda eficiente de similitud en vectores\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# Importaci√≥n de TextLoader para cargar archivos de texto plano (.txt) como documentos\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "# Importaci√≥n de YoutubeLoader para cargar transcripciones de videos de YouTube\n",
        "from langchain_community.document_loaders.youtube import YoutubeLoader\n",
        "\n",
        "# Importaci√≥n de ArxivLoader para buscar y cargar papers acad√©micos desde ArXiv\n",
        "from langchain_community.document_loaders import ArxivLoader\n",
        "\n",
        "# Importaci√≥n de RecursiveCharacterTextSplitter para dividir textos largos en chunks (fragmentos) de manera recursiva\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Importaci√≥n de WikipediaQueryRun para ejecutar b√∫squedas en Wikipedia\n",
        "from langchain.tools import WikipediaQueryRun\n",
        "\n",
        "# Importaci√≥n de WikipediaAPIWrapper, el wrapper que encapsula las llamadas a la API de Wikipedia\n",
        "from langchain.utilities import WikipediaAPIWrapper\n",
        "\n",
        "# Importaci√≥n de StateGraph para crear grafos de estado (flujos de trabajo con nodos y aristas)\n",
        "# END es un marcador especial que indica el final del grafo\n",
        "from langgraph.graph import StateGraph, END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importaci√≥n del m√≥dulo os para acceder a variables de entorno\n",
        "import os\n",
        "\n",
        "# Importaci√≥n de init_chat_model para inicializar modelos de chat de diferentes proveedores\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "# Importaci√≥n de load_dotenv para cargar variables de entorno desde un archivo .env\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Configuraci√≥n de la variable de entorno OPENAI_API_KEY con el valor obtenido del archivo .env\n",
        "# Esto permite autenticarse con la API de OpenAI\n",
        "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Inicializaci√≥n del modelo de lenguaje usando GPT-4o-mini de OpenAI\n",
        "# Se usa la versi√≥n 'mini' que es m√°s econ√≥mica y r√°pida, ideal para s√≠ntesis de informaci√≥n\n",
        "llm=init_chat_model(\"openai:gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funci√≥n para cargar y crear un retriever desde un archivo de texto\n",
        "def load_text_retriever(file_path):\n",
        "    \"\"\"\n",
        "    Carga un archivo de texto, lo divide en chunks y crea un retriever vectorial.\n",
        "    Esto permite buscar informaci√≥n relevante en documentos internos.\n",
        "    \"\"\"\n",
        "    # Carga del archivo de texto usando TextLoader\n",
        "    # encoding=\"utf-8\" asegura la correcta lectura de caracteres especiales y acentos\n",
        "    docs = TextLoader(file_path, encoding=\"utf-8\").load()\n",
        "    \n",
        "    # Creaci√≥n de un splitter (divisor) para fragmentar los documentos largos\n",
        "    # chunk_size=500: cada fragmento tendr√° aproximadamente 500 caracteres\n",
        "    # chunk_overlap=50: habr√° una superposici√≥n de 50 caracteres entre fragmentos consecutivos\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    \n",
        "    # Divisi√≥n de los documentos en chunks m√°s peque√±os\n",
        "    chunks = splitter.split_documents(docs)\n",
        "    \n",
        "    # Creaci√≥n de un vector store usando FAISS con los chunks y embeddings de OpenAI\n",
        "    vs = FAISS.from_documents(chunks, OpenAIEmbeddings())\n",
        "    \n",
        "    # Retorna el vector store convertido en retriever para b√∫squedas\n",
        "    return vs.as_retriever()\n",
        "\n",
        "# Funci√≥n para cargar un retriever simulado de transcripciones de YouTube\n",
        "def load_youtube_retriever():\n",
        "    \"\"\"\n",
        "    En este ejemplo, crea un retriever simulado con contenido de YouTube.\n",
        "    En producci√≥n, esto usar√≠a YoutubeLoader con URLs reales de videos.\n",
        "    \"\"\"\n",
        "    # Contenido simulado de una transcripci√≥n de YouTube sobre sistemas ag√©nticos de IA\n",
        "    # Este texto representa lo que se obtendr√≠a de un video real\n",
        "    content = \"\"\"\n",
        "    Este video explica c√≥mo los sistemas de IA ag√©nticos dependen de bucles de retroalimentaci√≥n, memoria y uso de herramientas.\n",
        "    Los compara con LLMs tradicionales basados en pipelines. Se enfatizan el razonamiento temporal y las tareas aut√≥nomas.\n",
        "    \"\"\"\n",
        "    # Creaci√≥n de un objeto Document con el contenido simulado y metadatos de origen\n",
        "    doc = Document(page_content=content, metadata={\"source\": \"youtube\"})\n",
        "    \n",
        "    # Creaci√≥n de un vector store con el documento simulado\n",
        "    vectorstore = FAISS.from_documents([doc], OpenAIEmbeddings())\n",
        "    \n",
        "    # Retorna el vector store convertido en retriever\n",
        "    return vectorstore.as_retriever()\n",
        "\n",
        "\n",
        "\n",
        "# Funci√≥n para buscar informaci√≥n en Wikipedia\n",
        "def wikipedia_search(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Realiza una b√∫squeda en Wikipedia y retorna el contenido relevante.\n",
        "    √ötil para obtener informaci√≥n general y contextual sobre temas amplios.\n",
        "    \"\"\"\n",
        "    # Imprime un mensaje indicando que se est√° buscando en Wikipedia\n",
        "    print(\"üåê Buscando en Wikipedia...\")\n",
        "    \n",
        "    # Ejecuta la b√∫squeda usando WikipediaQueryRun con el wrapper de la API\n",
        "    # WikipediaAPIWrapper() maneja las llamadas HTTP a la API de Wikipedia\n",
        "    # (query) invoca la b√∫squeda con la consulta proporcionada\n",
        "    return WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())(query)\n",
        "\n",
        "# Funci√≥n para buscar papers acad√©micos en ArXiv\n",
        "def arxiv_search(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Busca y carga papers acad√©micos desde ArXiv relacionados con la consulta.\n",
        "    Ideal para obtener informaci√≥n cient√≠fica actualizada y de investigaci√≥n.\n",
        "    \"\"\"\n",
        "    # Imprime un mensaje indicando que se est√° buscando en ArXiv\n",
        "    print(\"üìÑ Buscando en ArXiv...\")\n",
        "    \n",
        "    # Usa ArxivLoader para buscar papers relacionados con la consulta\n",
        "    # .load() descarga y procesa los papers encontrados\n",
        "    results = ArxivLoader(query).load()\n",
        "    \n",
        "    # Concatena el contenido de los primeros 2 papers ([:2]) separados por doble salto de l√≠nea\n",
        "    # Si no hay resultados, retorna un mensaje indicando que no se encontraron papers\n",
        "    # 'or' act√∫a como operador de respaldo: si el string est√° vac√≠o, retorna el mensaje\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in results[:2]) or \"No se encontraron papers relevantes.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creaci√≥n de los retrievers que se usar√°n para b√∫squeda de informaci√≥n\n",
        "\n",
        "# text_retriever: retriever para documentos internos de texto\n",
        "# Carga y procesa el archivo \"internal_docs.txt\" para b√∫squedas vectoriales\n",
        "text_retriever = load_text_retriever(\"internal_docs.txt\")\n",
        "\n",
        "# youtube_retriever: retriever para contenido de YouTube (en este caso, simulado)\n",
        "# En producci√≥n, esto cargar√≠a transcripciones reales de videos de YouTube\n",
        "youtube_retriever = load_youtube_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Estado del grafo para RAG multi-fuente\n",
        "\n",
        "# Clase que define el estado del flujo de trabajo para s√≠ntesis de m√∫ltiples fuentes\n",
        "# Hereda de BaseModel (Pydantic) para validaci√≥n autom√°tica de tipos y datos\n",
        "class MultiSourceRAGState(BaseModel):\n",
        "    # question: la pregunta original del usuario (tipo string, campo obligatorio)\n",
        "    question: str\n",
        "    \n",
        "    # text_docs: lista de documentos recuperados de archivos de texto internos\n",
        "    # Por defecto es una lista vac√≠a []\n",
        "    # Contiene fragmentos relevantes de los documentos internos\n",
        "    text_docs: List[Document] = []\n",
        "    \n",
        "    # yt_docs: lista de documentos recuperados de transcripciones de YouTube\n",
        "    # Por defecto es una lista vac√≠a []\n",
        "    # Contiene informaci√≥n de videos relacionados con la consulta\n",
        "    yt_docs: List[Document] = []\n",
        "    \n",
        "    # wiki_context: contexto/informaci√≥n recuperada de Wikipedia\n",
        "    # Por defecto es una cadena vac√≠a \"\"\n",
        "    # Contiene el texto completo retornado por la b√∫squeda en Wikipedia\n",
        "    wiki_context: str = \"\"\n",
        "    \n",
        "    # arxiv_context: contexto/informaci√≥n recuperada de papers acad√©micos en ArXiv\n",
        "    # Por defecto es una cadena vac√≠a \"\"\n",
        "    # Contiene fragmentos de papers cient√≠ficos relevantes\n",
        "    arxiv_context: str = \"\"\n",
        "    \n",
        "    # final_answer: la respuesta final sintetizada que combina informaci√≥n de todas las fuentes\n",
        "    # Por defecto es una cadena vac√≠a \"\"\n",
        "    # Esta es la respuesta coherente y completa que se presenta al usuario\n",
        "    final_answer: str = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Nodos de Recuperaci√≥n - cada uno obtiene informaci√≥n de una fuente diferente\n",
        "\n",
        "# Nodo 1: Recuperar documentos de texto internos\n",
        "def retrieve_text(state: MultiSourceRAGState) -> MultiSourceRAGState:\n",
        "    \"\"\"\n",
        "    Recupera documentos relevantes de archivos de texto internos.\n",
        "    Primera fuente de informaci√≥n: documentaci√≥n interna de la empresa.\n",
        "    \"\"\"\n",
        "    # Invoca el retriever de texto con la pregunta del usuario\n",
        "    # Busca fragmentos similares sem√°nticamente en los documentos internos\n",
        "    docs = text_retriever.invoke(state.question)\n",
        "    \n",
        "    # Retorna una copia actualizada del estado con los documentos de texto\n",
        "    return state.model_copy(update={\"text_docs\": docs})\n",
        "\n",
        "# Nodo 2: Recuperar contenido de YouTube\n",
        "def retrieve_yt(state: MultiSourceRAGState) -> MultiSourceRAGState:\n",
        "    \"\"\"\n",
        "    Recupera informaci√≥n de transcripciones de videos de YouTube.\n",
        "    Segunda fuente: contenido multimedia/educativo de YouTube.\n",
        "    \"\"\"\n",
        "    # Invoca el retriever de YouTube con la pregunta del usuario\n",
        "    # Busca contenido relevante en las transcripciones de video\n",
        "    docs = youtube_retriever.invoke(state.question)\n",
        "    \n",
        "    # Retorna una copia actualizada del estado con los documentos de YouTube\n",
        "    return state.model_copy(update={\"yt_docs\": docs})\n",
        "\n",
        "# Nodo 3: Recuperar informaci√≥n de Wikipedia\n",
        "def retrieve_wikipedia(state: MultiSourceRAGState) -> MultiSourceRAGState:\n",
        "    \"\"\"\n",
        "    Busca y recupera informaci√≥n general de Wikipedia.\n",
        "    Tercera fuente: conocimiento enciclop√©dico p√∫blico.\n",
        "    \"\"\"\n",
        "    # Llama a la funci√≥n de b√∫squeda de Wikipedia con la pregunta del usuario\n",
        "    # Obtiene art√≠culos y contenido relevante de la enciclopedia\n",
        "    result = wikipedia_search(state.question)\n",
        "    \n",
        "    # Retorna una copia actualizada del estado con el contexto de Wikipedia\n",
        "    return state.model_copy(update={\"wiki_context\": result})\n",
        "\n",
        "# Nodo 4: Recuperar papers de ArXiv\n",
        "def retrieve_arxiv(state: MultiSourceRAGState) -> MultiSourceRAGState:\n",
        "    \"\"\"\n",
        "    Busca y recupera papers acad√©micos de ArXiv.\n",
        "    Cuarta fuente: investigaci√≥n cient√≠fica y acad√©mica actualizada.\n",
        "    \"\"\"\n",
        "    # Llama a la funci√≥n de b√∫squeda de ArXiv con la pregunta del usuario\n",
        "    # Obtiene papers relevantes de investigaci√≥n cient√≠fica\n",
        "    result = arxiv_search(state.question)\n",
        "    \n",
        "    # Retorna una copia actualizada del estado con el contexto de ArXiv\n",
        "    return state.model_copy(update={\"arxiv_context\": result})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Nodo de S√≠ntesis - combina toda la informaci√≥n en una respuesta coherente\n",
        "\n",
        "def synthesize_answer(state: MultiSourceRAGState) -> MultiSourceRAGState:\n",
        "    \"\"\"\n",
        "    Funci√≥n central que sintetiza informaci√≥n de todas las fuentes en una respuesta unificada.\n",
        "    Combina: documentos internos + YouTube + Wikipedia + ArXiv.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Inicializaci√≥n de una cadena vac√≠a que contendr√° todo el contexto combinado\n",
        "    context = \"\"\n",
        "\n",
        "    # Agregado de contexto de documentos internos\n",
        "    # Se a√±ade un encabezado \"[Documentos Internos]\" para identificar la fuente\n",
        "    # Se concatena el contenido de cada documento separado por saltos de l√≠nea\n",
        "    context += \"\\n\\n[Documentos Internos]\\n\" + \"\\n\".join([doc.page_content for doc in state.text_docs])\n",
        "    \n",
        "    # Agregado de contexto de transcripciones de YouTube\n",
        "    # Se a√±ade un encabezado \"[Transcripci√≥n de YouTube]\" para identificar la fuente\n",
        "    context += \"\\n\\n[Transcripci√≥n de YouTube]\\n\" + \"\\n\".join([doc.page_content for doc in state.yt_docs])\n",
        "    \n",
        "    # Agregado de contexto de Wikipedia\n",
        "    # Se a√±ade un encabezado \"[Wikipedia]\" seguido del contenido recuperado\n",
        "    context += \"\\n\\n[Wikipedia]\\n\" + state.wiki_context\n",
        "    \n",
        "    # Agregado de contexto de ArXiv\n",
        "    # Se a√±ade un encabezado \"[ArXiv]\" seguido de los papers acad√©micos\n",
        "    context += \"\\n\\n[ArXiv]\\n\" + state.arxiv_context\n",
        "\n",
        "    # Construcci√≥n del prompt para el LLM\n",
        "    # Se le pide expl√≠citamente que sintetice la informaci√≥n de m√∫ltiples fuentes\n",
        "    # El prompt incluye la pregunta y todo el contexto organizado por fuentes\n",
        "    prompt = f\"\"\"Has recuperado contexto relevante de m√∫ltiples fuentes. Ahora sintetiza una respuesta completa y coherente.\n",
        "\n",
        "Pregunta: {state.question}\n",
        "\n",
        "Contexto:\n",
        "{context}\n",
        "\n",
        "Respuesta Final:\"\"\"\n",
        "\n",
        "    # Invocaci√≥n del LLM con el prompt completo\n",
        "    # El LLM analiza toda la informaci√≥n de las cuatro fuentes y genera una respuesta sintetizada\n",
        "    # .content.strip() extrae el texto de la respuesta y elimina espacios en blanco\n",
        "    answer = llm.invoke(prompt).content.strip()\n",
        "    \n",
        "    # Retorna el estado actualizado con la respuesta final sintetizada\n",
        "    return state.model_copy(update={\"final_answer\": answer})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creaci√≥n del constructor del grafo de estado usando la clase MultiSourceRAGState\n",
        "# Este grafo implementa un flujo secuencial de recuperaci√≥n desde m√∫ltiples fuentes\n",
        "builder = StateGraph(MultiSourceRAGState)\n",
        "\n",
        "# Agregado de nodos al grafo - cada uno representa una fuente de informaci√≥n\n",
        "\n",
        "# Nodo para recuperar documentos de texto internos\n",
        "builder.add_node(\"retrieve_text\", retrieve_text)\n",
        "\n",
        "# Nodo para recuperar transcripciones de YouTube\n",
        "builder.add_node(\"retrieve_yt\", retrieve_yt)\n",
        "\n",
        "# Nodo para buscar informaci√≥n en Wikipedia\n",
        "builder.add_node(\"retrieve_wiki\", retrieve_wikipedia)\n",
        "\n",
        "# Nodo para buscar papers acad√©micos en ArXiv\n",
        "builder.add_node(\"retrieve_arxiv\", retrieve_arxiv)\n",
        "\n",
        "# Nodo para sintetizar toda la informaci√≥n en una respuesta coherente\n",
        "builder.add_node(\"synthesize\", synthesize_answer)\n",
        "\n",
        "# Establecer el punto de entrada del grafo (primer nodo a ejecutar)\n",
        "# El flujo comienza recuperando documentos de texto internos\n",
        "builder.set_entry_point(\"retrieve_text\")\n",
        "\n",
        "# Definici√≥n de aristas (edges) - flujo secuencial de recuperaci√≥n\n",
        "\n",
        "# Paso 1: Despu√©s de recuperar texto, ir a YouTube\n",
        "builder.add_edge(\"retrieve_text\", \"retrieve_yt\")\n",
        "\n",
        "# Paso 2: Despu√©s de YouTube, ir a Wikipedia\n",
        "builder.add_edge(\"retrieve_yt\", \"retrieve_wiki\")\n",
        "\n",
        "# Paso 3: Despu√©s de Wikipedia, ir a ArXiv\n",
        "builder.add_edge(\"retrieve_wiki\", \"retrieve_arxiv\")\n",
        "\n",
        "# Paso 4: Despu√©s de ArXiv (todas las fuentes recuperadas), sintetizar la respuesta\n",
        "builder.add_edge(\"retrieve_arxiv\", \"synthesize\")\n",
        "\n",
        "# Paso 5: Despu√©s de sintetizar, terminar el flujo\n",
        "builder.add_edge(\"synthesize\", END)\n",
        "\n",
        "# Compilaci√≥n del grafo para hacerlo ejecutable\n",
        "# .compile() valida la estructura y optimiza el grafo final\n",
        "graph = builder.compile()\n",
        "\n",
        "# Mostrar el grafo compilado (en Jupyter esto puede renderizar una visualizaci√≥n)\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definici√≥n de la pregunta del usuario\n",
        "# Esta es una pregunta compleja que requiere informaci√≥n de m√∫ltiples fuentes:\n",
        "# - Documentos internos sobre implementaciones espec√≠ficas\n",
        "# - YouTube para explicaciones conceptuales\n",
        "# - Wikipedia para definiciones generales\n",
        "# - ArXiv para investigaci√≥n reciente\n",
        "question = \"¬øQu√© son los agentes transformers y c√≥mo est√°n evolucionando en la investigaci√≥n reciente?\"\n",
        "\n",
        "# Creaci√≥n del estado inicial con solo la pregunta del usuario\n",
        "# Los dem√°s campos (text_docs, yt_docs, wiki_context, arxiv_context, final_answer) usar√°n sus valores por defecto\n",
        "state = MultiSourceRAGState(question=question)\n",
        "\n",
        "# Invocaci√≥n del grafo con el estado inicial\n",
        "# .invoke() ejecuta todo el flujo secuencial:\n",
        "# 1. Recupera de documentos internos\n",
        "# 2. Recupera de YouTube\n",
        "# 3. Recupera de Wikipedia\n",
        "# 4. Recupera de ArXiv\n",
        "# 5. Sintetiza toda la informaci√≥n en una respuesta coherente\n",
        "result = graph.invoke(state)\n",
        "\n",
        "# Impresi√≥n de la respuesta final sintetizada\n",
        "# Esta respuesta combina informaci√≥n de las cuatro fuentes diferentes\n",
        "# proporcionando una visi√≥n completa y multidimensional del tema\n",
        "print(\"‚úÖ Respuesta Final:\\n\")\n",
        "print(result[\"final_answer\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mostrar el estado final completo para inspecci√≥n y depuraci√≥n\n",
        "# Esto incluye todos los campos:\n",
        "# - question: la pregunta original\n",
        "# - text_docs: documentos recuperados de archivos internos\n",
        "# - yt_docs: documentos recuperados de YouTube\n",
        "# - wiki_context: contexto de Wikipedia\n",
        "# - arxiv_context: contexto de ArXiv\n",
        "# - final_answer: respuesta sintetizada final\n",
        "# √ötil para ver exactamente qu√© informaci√≥n se recuper√≥ de cada fuente\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
